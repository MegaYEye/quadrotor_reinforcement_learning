@article{cad2rl,
  author    = {Fereshteh Sadeghi and
               Sergey Levine},
  title     = {CAD2RL: Real Single-Image Flight
               without a Single Real Image},
  journal   = {CoRR},
  volume    = {abs/1611.04201},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.04201},
  archivePrefix = {arXiv},
  eprint    = {1611.04201},
  timestamp = {Wed, 07 Jun 2017 14:40:35 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/SadeghiL16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{airsim2017fsr,
    author = {Shital Shah and Debadeepta Dey and Chris Lovett and Ashish Kapoor},
    title = {AirSim: High-Fidelity Visual and Physical Simulation for Autonomous Vehicles},
    year = {2017},
    booktitle = {Field and Service Robotics},
    eprint = {arXiv:1705.05065},
    url = {https://arxiv.org/abs/1705.05065}
}

@misc{mnih2013playing,
    abstract = {We present the first deep learning model to successfully learn control
        policies directly from high-dimensional sensory input using reinforcement
            learning. The model is a convolutional neural network, trained with a variant
            of Q-learning, whose input is raw pixels and whose output is a value function
            estimating future rewards. We apply our method to seven Atari 2600 games from
            the Arcade Learning Environment, with no adjustment of the architecture or
            learning algorithm. We find that it outperforms all previous approaches on six
            of the games and surpasses a human expert on three of them.},
    added-at = {2014-12-14T17:55:47.000+0100},
    author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
    biburl = {https://www.bibsonomy.org/bibtex/2f4760edc252cd402821a341bda0026bf/vch},
    description = {Playing Atari with Deep Reinforcement Learning},
    interhash = {78966703f649bae69a08a6a23a4e8879},
    intrahash = {f4760edc252cd402821a341bda0026bf},
    keywords = {arxiv cs},
    note = {cite arxiv:1312.5602Comment: NIPS Deep Learning Workshop 2013},
    timestamp = {2014-12-14T17:55:47.000+0100},
    title = {Playing Atari with Deep Reinforcement Learning},
    url = {http://arxiv.org/abs/1312.5602},
    year = 2013
}



@article{mnih2015humanlevel,
    added-at = {2015-08-26T14:46:40.000+0200},
    author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
    biburl = {https://www.bibsonomy.org/bibtex/2fb15f4471c81dc2b9edf2304cb2f7083/hotho},
    description = {Human-level control through deep reinforcement learning - nature14236.pdf},
    interhash = {eac59980357d99db87b341b61ef6645f},
    intrahash = {fb15f4471c81dc2b9edf2304cb2f7083},
    issn = {00280836},
    journal = {Nature},
    keywords = {deep learning toread},
    month = feb,
    number = 7540,
    pages = {529--533},
    publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
    timestamp = {2015-08-26T14:46:40.000+0200},
    title = {Human-level control through deep reinforcement learning},
    url = {http://dx.doi.org/10.1038/nature14236},
    volume = 518,
    year = 2015
}
